{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "import imageio\n",
    "import facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /home/ovuser/FaceRecognition/models/20170512-110547\n",
      "Metagraph file: model-20170512-110547.meta\n",
      "Checkpoint file: model-20170512-110547.ckpt-250000\n",
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from /home/ovuser/FaceRecognition/models/20170512-110547/model-20170512-110547.ckpt-250000\n",
      "Tensor(\"Shape_5:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 1 and 4 for 'Assign_1' (op: 'Assign') with input shapes: [32], [3,3,3,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38966616f725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwts_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mmm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Facenet/Conv2d_1a_3x3/BatchNorm/moving_mean:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_bn_mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mmv_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Facenet/Conv2d_1a_3x3/BatchNorm/moving_variance:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmv_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_bn_mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.pyc\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    272\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    273\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    275\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.pyc\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     41\u001b[0m   result = _op_def_lib.apply_op(\"Assign\", ref=ref, value=value,\n\u001b[1;32m     42\u001b[0m                                 \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 1 and 4 for 'Assign_1' (op: 'Assign') with input shapes: [32], [3,3,3,32]."
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            facenet.load_model('/home/ovuser/FaceRecognition/models/20170512-110547')\n",
    "            all_tensors = tf.contrib.graph_editor.get_tensors(tf.get_default_graph())\n",
    "            all_tensor_names = [tensor.name for tensor in all_tensors]\n",
    "        \n",
    "            conv1_tensor_index = all_tensor_names.index('InceptionResnetV1/Conv2d_1a_3x3/weights:0')\n",
    "            conv1_weights = all_tensors[conv1_tensor_index].eval()\n",
    "            conv1_bn_mm_tensor_index = all_tensor_names.index('InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/moving_mean:0')\n",
    "            conv1_bn_mm = all_tensors[conv1_tensor_index].eval()\n",
    "            conv1_bn_mv_tensor_index = all_tensor_names.index('InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/moving_variance:0')\n",
    "            conv1_bn_mv = all_tensors[conv1_tensor_index].eval()\n",
    "            conv1_bn_beta_tensor_index = all_tensor_names.index('InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/beta:0')\n",
    "            conv1_bn_beta = all_tensors[conv1_tensor_index].eval()\n",
    "            \n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "    \n",
    "            inputs = tf.placeholder(dtype = tf.float32, shape = (None, 160, 160, 3))\n",
    "            with tf.variable_scope('Facenet', 'Facenet', [inputs], reuse=None):\n",
    "                with slim.arg_scope([slim.batch_norm, slim.dropout],\n",
    "                            is_training=False):\n",
    "                    with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "                                stride=1, padding='SAME'):\n",
    "      \n",
    "                        # 149 x 149 x 32\n",
    "                        net = slim.conv2d(inputs, 32, 3, stride=2, padding='VALID',\n",
    "                                  scope='Conv2d_1a_3x3', normalizer_fn = slim.batch_norm)\n",
    "                        \n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            wts_tensor = tf.get_default_graph().get_tensor_by_name(\"Facenet/Conv2d_1a_3x3/weights:0\")\n",
    "            print (tf.shape(wts_tensor))\n",
    "            tf.assign(wts_tensor, conv1_weights)\n",
    "            mm_tensor = tf.get_default_graph().get_tensor_by_name(\"Facenet/Conv2d_1a_3x3/BatchNorm/moving_mean:0\")\n",
    "            tf.assign(mm_tensor, conv1_bn_mm)\n",
    "            mv_tensor = tf.get_default_graph().get_tensor_by_name(\"Facenet/Conv2d_1a_3x3/BatchNorm/moving_variance:0\")\n",
    "            tf.assign(mv_tensor, conv1_bn_mv)\n",
    "            beta_tensor = tf.get_default_graph().get_tensor_by_name(\"Facenet/Conv2d_1a_3x3/BatchNorm/beta:0\")\n",
    "            tf.assign(beta_tensor, conv1_bn_beta)\n",
    "            output_tensor = tf.get_default_graph().get_tensor_by_name(\"InceptionResnetV1/Conv2d_1a_3x3/Relu:0\")\n",
    "            \n",
    "            im = imageio.imread('/home/ovuser/Pictures/kduncan_48.png')\n",
    "            images = [im]\n",
    "            feed_dict = {inputs: images}\n",
    "            emb_list = sess.run(net, feed_dict=feed_dict)\n",
    "            #all_tensors = tf.contrib.graph_editor.get_tensors(tf.get_default_graph())\n",
    "            #all_tensor_names = [tensor.name for tensor in all_tensors]\n",
    "            #print (all_tensor_names)\n",
    "            feed_dict = {images_placeholder: images}\n",
    "            facenet_emb_list = sess.run(output_tensor, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[75.32163     0.          0.         ...  0.         23.59276\n",
      "     0.        ]\n",
      "   [74.29479     0.          0.         ...  0.         22.440212\n",
      "     0.        ]\n",
      "   [74.89318     0.          0.         ...  0.         21.934326\n",
      "     0.        ]\n",
      "   ...\n",
      "   [71.14871     0.          0.         ...  0.         23.772858\n",
      "     0.        ]\n",
      "   [72.07695     0.          0.         ...  0.         23.078848\n",
      "     0.        ]\n",
      "   [72.77179     0.          0.         ...  0.         23.10966\n",
      "     0.        ]]\n",
      "\n",
      "  [[74.065506    0.          0.         ...  0.         24.118254\n",
      "     0.        ]\n",
      "   [73.17446     0.          0.         ...  0.         23.218664\n",
      "     0.        ]\n",
      "   [74.82022     0.          0.         ...  0.         21.92794\n",
      "     0.        ]\n",
      "   ...\n",
      "   [71.4891      0.          0.         ...  0.         24.001389\n",
      "     0.        ]\n",
      "   [71.51665     0.          0.         ...  0.         23.601269\n",
      "     0.        ]\n",
      "   [71.89565     0.          0.         ...  0.         22.943272\n",
      "     0.        ]]\n",
      "\n",
      "  [[72.63567     0.          0.         ...  0.         23.56405\n",
      "     0.        ]\n",
      "   [72.03235     0.          0.         ...  0.         23.83204\n",
      "     0.        ]\n",
      "   [73.96141     0.          0.         ...  0.         23.930231\n",
      "     0.        ]\n",
      "   ...\n",
      "   [71.57519     0.          0.         ...  0.         22.815893\n",
      "     0.        ]\n",
      "   [71.28031     0.          0.         ...  0.         23.529556\n",
      "     0.        ]\n",
      "   [71.19253     0.          0.         ...  0.         22.636225\n",
      "     0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[70.13284     0.          0.         ...  0.         24.03457\n",
      "     0.        ]\n",
      "   [68.77753     0.          0.         ...  0.         24.634907\n",
      "     0.        ]\n",
      "   [70.02782     0.          0.         ...  0.         24.5111\n",
      "     0.        ]\n",
      "   ...\n",
      "   [20.792593    0.          0.         ...  0.          0.31241536\n",
      "     0.        ]\n",
      "   [19.741114    0.85131365  0.         ...  0.          4.914768\n",
      "     0.        ]\n",
      "   [22.863297    1.9311194   0.         ...  0.         15.642565\n",
      "     0.        ]]\n",
      "\n",
      "  [[69.31234     0.          0.         ...  0.         24.615757\n",
      "     0.        ]\n",
      "   [69.02925     0.          0.         ...  0.         24.153738\n",
      "     0.        ]\n",
      "   [69.00586     0.          0.         ...  0.         25.066114\n",
      "     0.        ]\n",
      "   ...\n",
      "   [21.04818     0.          0.         ...  0.          2.7094946\n",
      "     0.        ]\n",
      "   [16.392796    0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [22.103054    0.          0.         ...  0.          1.6666467\n",
      "     0.        ]]\n",
      "\n",
      "  [[69.94525     0.          0.         ...  0.         25.97368\n",
      "     0.        ]\n",
      "   [69.62532     0.          0.         ...  0.         25.621914\n",
      "     0.        ]\n",
      "   [69.98495     0.          0.         ...  0.         24.605188\n",
      "     0.        ]\n",
      "   ...\n",
      "   [31.300259    0.          0.         ...  0.          0.\n",
      "     5.429752  ]\n",
      "   [28.636778    0.          0.         ...  0.          0.\n",
      "     7.515171  ]\n",
      "   [27.790611    0.          0.         ...  0.          0.\n",
      "     5.6725416 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print (emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
