{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "from scipy import misc\n",
    "import caffe\n",
    "\n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y\n",
    "\n",
    "def max_diff(layer_1, layer_2):\n",
    "    diff_array = np.absolute(np.subtract(layer_1, layer_2))\n",
    "    max_d = np.amax(diff_array)\n",
    "    print ('Max abs diff: ', max_d)\n",
    "    return max_d\n",
    "\n",
    "def read_images(input_image_names, io = 'caffe', output= 'caffe', transpose = (2, 0, 1)):\n",
    "    if io=='caffe':\n",
    "        inputs =[prewhiten(caffe.io.load_image(im_f)) for im_f in input_image_names]\n",
    "        if output == 'caffe':\n",
    "            transformed_images = [image.transpose(transpose) for image in inputs]#transformer.preprocess('data', image)\n",
    "        else:\n",
    "            transformed_images = inputs\n",
    "        inputs = transformed_images\n",
    "    elif io == 'misc':\n",
    "        inputs =[prewhiten(misc.imread(im_f)) for im_f in input_image_names] \n",
    "        if output == 'caffe':\n",
    "            transformed_images = [image.transpose(transpose) for image in inputs]#transformer.preprocess('data', image)\n",
    "        else:\n",
    "            transformed_images = inputs\n",
    "        inputs = transformed_images\n",
    "    else:\n",
    "        print ('Invaid IO mode...!')\n",
    "    return inputs\n",
    "\n",
    "def get_embeddings_caffe(inputs, output_layer = 'normed_features', model_def = '/home/ovuser/Projects/tf_2_caffe/facenet_deploy.prototxt', pretrained_model = '/home/ovuser/Projects/tf_2_caffe/inc_resnet_v1_facenet.caffemodel', gpu = True):\n",
    "    #pycaffe_dir = os.path.dirname(__file__)\n",
    "    if gpu:\n",
    "        caffe.set_mode_gpu()\n",
    "        print(\"GPU mode\")\n",
    "    else:\n",
    "        caffe.set_mode_cpu()\n",
    "        print(\"CPU mode\")\n",
    "\n",
    "    # Make classifier.\n",
    "    classifier = caffe.Net(model_def, pretrained_model, caffe.TEST)\n",
    "    print(\"Classifying %d inputs.\" % len(inputs))    \n",
    "    outputs = []\n",
    "    start = time.time()\n",
    "    for transformed_image in inputs:\n",
    "        # Classify.\n",
    "        # copy the image data into the memory allocated for the net\n",
    "        classifier.blobs['data'].data[...] = transformed_image\n",
    "        ### perform classification\n",
    "        output = classifier.forward()[output_layer][0].copy()\n",
    "        outputs.append(output)\n",
    "    print(\"Done in %.2f s.\" % (time.time() - start))\n",
    "    return outputs\n",
    "\n",
    "def tf_fwd_pass(images, output_layers, model_dir = '/home/ovuser/FaceRecognition/models/20170512-110547'):\n",
    "    import tensorflow as tf\n",
    "    import facenet\n",
    "    outputs = []\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            #Load the model\n",
    "            facenet.load_model(model_dir)\n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            feed_dict = { images_placeholder: images, phase_train_placeholder:False }\n",
    "            for tensor_name in output_layers:\n",
    "                tensor = tf.get_default_graph().get_tensor_by_name(tensor_name) \n",
    "                outputs.append(sess.run(tensor, feed_dict=feed_dict))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset = '/home/ovuser/Pictures/panel-data-aligned/'\n",
    "subjects = [dataset+subject for subject in os.listdir(dataset)]\n",
    "input_image_names = []\n",
    "for subject in subjects:\n",
    "    input_image_names.extend([subject+'/'+image for image in os.listdir(subject)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_images = read_images(input_image_names, 'misc', 'caffe')\n",
    "tf_images = read_images(input_image_names, 'misc', 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_images = read_images(['/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_41.png'], 'caffe', 'caffe')\n",
    "tf_images = read_images(['/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_41.png'], 'caffe', 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU mode\n",
      "Classifying 10 inputs.\n",
      "Done in 0.55 s.\n"
     ]
    }
   ],
   "source": [
    "caffe_outputs = get_embeddings_caffe(caffe_images[:10], output_layer = 'normed_features', model_def = '/home/ovuser/Projects/tf_2_caffe/facenet_deploy.prototxt', pretrained_model = '/home/ovuser/Projects/tf_2_caffe/inc_resnet_v1_facenet_latest_5_15.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_layers = ['embeddings:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /home/ovuser/FaceRecognition/models/20170512-110547\n",
      "Metagraph file: model-20170512-110547.meta\n",
      "Checkpoint file: model-20170512-110547.ckpt-250000\n",
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from /home/ovuser/FaceRecognition/models/20170512-110547/model-20170512-110547.ckpt-250000\n"
     ]
    }
   ],
   "source": [
    "tf_outputs = tf_fwd_pass(tf_images[:10], tf_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_41.png\n",
      "True\n",
      "('Max abs diff: ', 1.296401e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_22.png\n",
      "True\n",
      "('Max abs diff: ', 1.5607104e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_7.png\n",
      "True\n",
      "('Max abs diff: ', 1.50753185e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_34.png\n",
      "True\n",
      "('Max abs diff: ', 2.6457012e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_19.png\n",
      "True\n",
      "('Max abs diff: ', 1.1220574e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_30.png\n",
      "True\n",
      "('Max abs diff: ', 1.316797e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_18.png\n",
      "True\n",
      "('Max abs diff: ', 1.0591e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_26.png\n",
      "True\n",
      "('Max abs diff: ', 1.6897917e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_31.png\n",
      "True\n",
      "('Max abs diff: ', 1.4953315e-05)\n",
      "/home/ovuser/Pictures/panel-data-aligned/deubanks/deubanks_10.png\n",
      "True\n",
      "('Max abs diff: ', 2.3297966e-05)\n"
     ]
    }
   ],
   "source": [
    "diff = []\n",
    "for i in range(len(caffe_outputs)):\n",
    "    print (input_image_names[i])\n",
    "    print (np.array_equal(tf_images[i], caffe_images[i].transpose(1,2,0)))\n",
    "    #print (caffe_outputs[i].shape, tf_outputs[0][i].shape)\n",
    "    #print (caffe_outputs[i][:10], tf_outputs[0][i][:10])\n",
    "    diff.append(max_diff(caffe_outputs[i], tf_outputs[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.sum(np.square(caffe_outputs[0])), np.sum(np.square(tf_outputs[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (input_image_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "for i in range(len(caffe_outputs)):\n",
    "    print (input_image_names[i])\n",
    "    print (np.array_equal(tf_images[i], caffe_images[i].transpose(1,2,0)))\n",
    "    #print (caffe_outputs[i].shape, tf_outputs[0][i].shape)\n",
    "    #print (caffe_outputs[i][:10], tf_outputs[0][i][:10])\n",
    "    diff.append(max_diff(caffe_outputs[i], tf_outputs[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deubanks_41_output_caffe = caffe_outputs[0]\n",
    "deubanks_41_output_tf = tf_outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print max_diff(deubanks_41_output_caffe, deubanks_41_output_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print max_diff(deubanks_41_output_caffe, caffe_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print max_diff(deubanks_41_output_tf, tf_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_individual_fwd_passes(input_image_names):\n",
    "    for image in input_image_names:\n",
    "        caffe_images = read_images([image], 'caffe', 'caffe')\n",
    "        tf_images = read_images([image], 'caffe', 'tf')\n",
    "        caffe_outputs = get_embeddings_caffe(caffe_images, output_layer = 'normed_features', model_def = '/home/ovuser/Projects/tf_2_caffe/facenet_deploy.prototxt', pretrained_model = '/home/ovuser/Projects/tf_2_caffe/inc_resnet_v1_facenet_latest_5_15.caffemodel')\n",
    "        tf_outputs = tf_fwd_pass(tf_images, ['embeddings:0'])\n",
    "        print (max_diff(caffe_outputs[0], tf_outputs[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_individual_fwd_passes(input_image_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
