input: "data"
input_dim: 1
input_dim: 3
input_dim: 256
input_dim: 256
layer {
  name: "conv1_3x3_s2"
  type: "Convolution"
  bottom: "data"
  top: "conv1_3x3_s2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "conv1_3x3_s2_bn_tr"
  type: "BatchNorm"
  bottom: "conv1_3x3_s2"
  top: "conv1_3x3_s2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv1_3x3_s2_bn"
  type: "BatchNorm"
  bottom: "conv1_3x3_s2"
  top: "conv1_3x3_s2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv1_3x3_s2_relu"
  type: "ReLU"
  bottom: "conv1_3x3_s2"
  top: "conv1_3x3_s2"
}
layer {
  name: "conv2_3x3_s1"
  type: "Convolution"
  bottom: "conv1_3x3_s2"
  top: "conv2_3x3_s1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "conv2_3x3_s1_bn_tr"
  type: "BatchNorm"
  bottom: "conv2_3x3_s1"
  top: "conv2_3x3_s1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv2_3x3_s1_bn"
  type: "BatchNorm"
  bottom: "conv2_3x3_s1"
  top: "conv2_3x3_s1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv2_3x3_s1_relu"
  type: "ReLU"
  bottom: "conv2_3x3_s1"
  top: "conv2_3x3_s1"
}
layer {
  name: "conv3_3x3_s1"
  type: "Convolution"
  bottom: "conv2_3x3_s1"
  top: "conv3_3x3_s1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "conv3_3x3_s1_bn_tr"
  type: "BatchNorm"
  bottom: "conv3_3x3_s1"
  top: "conv3_3x3_s1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv3_3x3_s1_bn"
  type: "BatchNorm"
  bottom: "conv3_3x3_s1"
  top: "conv3_3x3_s1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv3_3x3_s1_relu"
  type: "ReLU"
  bottom: "conv3_3x3_s1"
  top: "conv3_3x3_s1"
}
layer {
  name: "inception_stem1_pool"
  type: "Pooling"
  bottom: "conv3_3x3_s1"
  top: "inception_stem1_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv4_1x1_s1"
  type: "Convolution"
  bottom: "inception_stem1_pool"
  top: "conv4_1x1_s1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 80
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "conv4_1x1_s1_bn_tr"
  type: "BatchNorm"
  bottom: "conv4_1x1_s1"
  top: "conv4_1x1_s1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv4_1x1_s1_bn"
  type: "BatchNorm"
  bottom: "conv4_1x1_s1"
  top: "conv4_1x1_s1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv4_1x1_s1_relu"
  type: "ReLU"
  bottom: "conv4_1x1_s1"
  top: "conv4_1x1_s1"
}
layer {
  name: "conv5_3x3_s1"
  type: "Convolution"
  bottom: "conv4_1x1_s1"
  top: "conv5_3x3_s1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "conv5_3x3_s1_bn_tr"
  type: "BatchNorm"
  bottom: "conv5_3x3_s1"
  top: "conv5_3x3_s1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv5_3x3_s1_bn"
  type: "BatchNorm"
  bottom: "conv5_3x3_s1"
  top: "conv5_3x3_s1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv5_3x3_s1_relu"
  type: "ReLU"
  bottom: "conv5_3x3_s1"
  top: "conv5_3x3_s1"
}
layer {
  name: "conv6_3x3_s2"
  type: "Convolution"
  bottom: "conv5_3x3_s1"
  top: "conv6_3x3_s2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "conv6_3x3_s2_bn_tr"
  type: "BatchNorm"
  bottom: "conv6_3x3_s2"
  top: "conv6_3x3_s2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv6_3x3_s2_bn"
  type: "BatchNorm"
  bottom: "conv6_3x3_s2"
  top: "conv6_3x3_s2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "conv6_3x3_s2_relu"
  type: "ReLU"
  bottom: "conv6_3x3_s2"
  top: "conv6_3x3_s2"
}
layer {
  name: "inception_a1_1x1_b0"
  type: "Convolution"
  bottom: "conv6_3x3_s2"
  top: "inception_a1_1x1_b0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a1_1x1_b0_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a1_1x1_b0"
  top: "inception_a1_1x1_b0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_1x1_b0_bn"
  type: "BatchNorm"
  bottom: "inception_a1_1x1_b0"
  top: "inception_a1_1x1_b0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_1x1_b0_relu"
  type: "ReLU"
  bottom: "inception_a1_1x1_b0"
  top: "inception_a1_1x1_b0"
}
layer {
  name: "inception_a1_1x1_b1"
  type: "Convolution"
  bottom: "conv6_3x3_s2"
  top: "inception_a1_1x1_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a1_1x1_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a1_1x1_b1"
  top: "inception_a1_1x1_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_1x1_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a1_1x1_b1"
  top: "inception_a1_1x1_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_1x1_b1_relu"
  type: "ReLU"
  bottom: "inception_a1_1x1_b1"
  top: "inception_a1_1x1_b1"
}
layer {
  name: "inception_a1_3x3_b1"
  type: "Convolution"
  bottom: "inception_a1_1x1_b1"
  top: "inception_a1_3x3_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a1_3x3_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a1_3x3_b1"
  top: "inception_a1_3x3_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_3x3_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a1_3x3_b1"
  top: "inception_a1_3x3_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_3x3_b1_relu"
  type: "ReLU"
  bottom: "inception_a1_3x3_b1"
  top: "inception_a1_3x3_b1"
}
layer {
  name: "inception_a1_1x1_b2"
  type: "Convolution"
  bottom: "conv6_3x3_s2"
  top: "inception_a1_1x1_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a1_1x1_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a1_1x1_b2"
  top: "inception_a1_1x1_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_1x1_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a1_1x1_b2"
  top: "inception_a1_1x1_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_1x1_b2_relu"
  type: "ReLU"
  bottom: "inception_a1_1x1_b2"
  top: "inception_a1_1x1_b2"
}
layer {
  name: "inception_a1_3x3_b2"
  type: "Convolution"
  bottom: "inception_a1_1x1_b2"
  top: "inception_a1_3x3_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a1_3x3_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a1_3x3_b2"
  top: "inception_a1_3x3_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_3x3_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a1_3x3_b2"
  top: "inception_a1_3x3_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_3x3_b2_relu"
  type: "ReLU"
  bottom: "inception_a1_3x3_b2"
  top: "inception_a1_3x3_b2"
}
layer {
  name: "inception_a1_3x3_b2_a"
  type: "Convolution"
  bottom: "inception_a1_3x3_b2"
  top: "inception_a1_3x3_b2_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a1_3x3_b2_a_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a1_3x3_b2_a"
  top: "inception_a1_3x3_b2_a"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_3x3_b2_a_bn"
  type: "BatchNorm"
  bottom: "inception_a1_3x3_b2_a"
  top: "inception_a1_3x3_b2_a"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a1_3x3_b2_a_relu"
  type: "ReLU"
  bottom: "inception_a1_3x3_b2_a"
  top: "inception_a1_3x3_b2_a"
}
layer {
  name: "inception_a1_concat"
  type: "Concat"
  bottom: "inception_a1_1x1_b0"
  bottom: "inception_a1_3x3_b1"
  bottom: "inception_a1_3x3_b2_a"
  top: "inception_a1_concat"
}
layer {
  name: "inception_a1_1x1"
  type: "Convolution"
  bottom: "inception_a1_concat"
  top: "inception_a1_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_a1_scaled"
  type: "Power"
  bottom: "inception_a1_1x1"
  top: "inception_a1_scaled"
  power_param {
    power: 1.0
    scale: 0.170000001788
    shift: 0.0
  }
}
layer {
  name: "inception_a1_output"
  type: "Eltwise"
  bottom: "conv6_3x3_s2"
  bottom: "inception_a1_scaled"
  top: "inception_a1_output"
}
layer {
  name: "inception_a1_output_relu"
  type: "ReLU"
  bottom: "inception_a1_output"
  top: "inception_a1_output"
}
layer {
  name: "inception_a2_1x1_b0"
  type: "Convolution"
  bottom: "inception_a1_output"
  top: "inception_a2_1x1_b0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a2_1x1_b0_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a2_1x1_b0"
  top: "inception_a2_1x1_b0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_1x1_b0_bn"
  type: "BatchNorm"
  bottom: "inception_a2_1x1_b0"
  top: "inception_a2_1x1_b0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_1x1_b0_relu"
  type: "ReLU"
  bottom: "inception_a2_1x1_b0"
  top: "inception_a2_1x1_b0"
}
layer {
  name: "inception_a2_1x1_b1"
  type: "Convolution"
  bottom: "inception_a1_output"
  top: "inception_a2_1x1_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a2_1x1_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a2_1x1_b1"
  top: "inception_a2_1x1_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_1x1_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a2_1x1_b1"
  top: "inception_a2_1x1_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_1x1_b1_relu"
  type: "ReLU"
  bottom: "inception_a2_1x1_b1"
  top: "inception_a2_1x1_b1"
}
layer {
  name: "inception_a2_3x3_b1"
  type: "Convolution"
  bottom: "inception_a2_1x1_b1"
  top: "inception_a2_3x3_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a2_3x3_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a2_3x3_b1"
  top: "inception_a2_3x3_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_3x3_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a2_3x3_b1"
  top: "inception_a2_3x3_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_3x3_b1_relu"
  type: "ReLU"
  bottom: "inception_a2_3x3_b1"
  top: "inception_a2_3x3_b1"
}
layer {
  name: "inception_a2_1x1_b2"
  type: "Convolution"
  bottom: "inception_a1_output"
  top: "inception_a2_1x1_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a2_1x1_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a2_1x1_b2"
  top: "inception_a2_1x1_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_1x1_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a2_1x1_b2"
  top: "inception_a2_1x1_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_1x1_b2_relu"
  type: "ReLU"
  bottom: "inception_a2_1x1_b2"
  top: "inception_a2_1x1_b2"
}
layer {
  name: "inception_a2_3x3_b2"
  type: "Convolution"
  bottom: "inception_a2_1x1_b2"
  top: "inception_a2_3x3_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a2_3x3_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a2_3x3_b2"
  top: "inception_a2_3x3_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_3x3_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a2_3x3_b2"
  top: "inception_a2_3x3_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_3x3_b2_relu"
  type: "ReLU"
  bottom: "inception_a2_3x3_b2"
  top: "inception_a2_3x3_b2"
}
layer {
  name: "inception_a2_3x3_b2_a"
  type: "Convolution"
  bottom: "inception_a2_3x3_b2"
  top: "inception_a2_3x3_b2_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a2_3x3_b2_a_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a2_3x3_b2_a"
  top: "inception_a2_3x3_b2_a"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_3x3_b2_a_bn"
  type: "BatchNorm"
  bottom: "inception_a2_3x3_b2_a"
  top: "inception_a2_3x3_b2_a"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a2_3x3_b2_a_relu"
  type: "ReLU"
  bottom: "inception_a2_3x3_b2_a"
  top: "inception_a2_3x3_b2_a"
}
layer {
  name: "inception_a2_concat"
  type: "Concat"
  bottom: "inception_a2_1x1_b0"
  bottom: "inception_a2_3x3_b1"
  bottom: "inception_a2_3x3_b2_a"
  top: "inception_a2_concat"
}
layer {
  name: "inception_a2_1x1"
  type: "Convolution"
  bottom: "inception_a2_concat"
  top: "inception_a2_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_a2_scaled"
  type: "Power"
  bottom: "inception_a2_1x1"
  top: "inception_a2_scaled"
  power_param {
    power: 1.0
    scale: 0.170000001788
    shift: 0.0
  }
}
layer {
  name: "inception_a2_output"
  type: "Eltwise"
  bottom: "inception_a1_output"
  bottom: "inception_a2_scaled"
  top: "inception_a2_output"
}
layer {
  name: "inception_a2_output_relu"
  type: "ReLU"
  bottom: "inception_a2_output"
  top: "inception_a2_output"
}
layer {
  name: "inception_a3_1x1_b0"
  type: "Convolution"
  bottom: "inception_a2_output"
  top: "inception_a3_1x1_b0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a3_1x1_b0_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a3_1x1_b0"
  top: "inception_a3_1x1_b0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_1x1_b0_bn"
  type: "BatchNorm"
  bottom: "inception_a3_1x1_b0"
  top: "inception_a3_1x1_b0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_1x1_b0_relu"
  type: "ReLU"
  bottom: "inception_a3_1x1_b0"
  top: "inception_a3_1x1_b0"
}
layer {
  name: "inception_a3_1x1_b1"
  type: "Convolution"
  bottom: "inception_a2_output"
  top: "inception_a3_1x1_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a3_1x1_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a3_1x1_b1"
  top: "inception_a3_1x1_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_1x1_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a3_1x1_b1"
  top: "inception_a3_1x1_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_1x1_b1_relu"
  type: "ReLU"
  bottom: "inception_a3_1x1_b1"
  top: "inception_a3_1x1_b1"
}
layer {
  name: "inception_a3_3x3_b1"
  type: "Convolution"
  bottom: "inception_a3_1x1_b1"
  top: "inception_a3_3x3_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a3_3x3_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a3_3x3_b1"
  top: "inception_a3_3x3_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_3x3_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a3_3x3_b1"
  top: "inception_a3_3x3_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_3x3_b1_relu"
  type: "ReLU"
  bottom: "inception_a3_3x3_b1"
  top: "inception_a3_3x3_b1"
}
layer {
  name: "inception_a3_1x1_b2"
  type: "Convolution"
  bottom: "inception_a2_output"
  top: "inception_a3_1x1_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a3_1x1_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a3_1x1_b2"
  top: "inception_a3_1x1_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_1x1_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a3_1x1_b2"
  top: "inception_a3_1x1_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_1x1_b2_relu"
  type: "ReLU"
  bottom: "inception_a3_1x1_b2"
  top: "inception_a3_1x1_b2"
}
layer {
  name: "inception_a3_3x3_b2"
  type: "Convolution"
  bottom: "inception_a3_1x1_b2"
  top: "inception_a3_3x3_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a3_3x3_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a3_3x3_b2"
  top: "inception_a3_3x3_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_3x3_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a3_3x3_b2"
  top: "inception_a3_3x3_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_3x3_b2_relu"
  type: "ReLU"
  bottom: "inception_a3_3x3_b2"
  top: "inception_a3_3x3_b2"
}
layer {
  name: "inception_a3_3x3_b2_a"
  type: "Convolution"
  bottom: "inception_a3_3x3_b2"
  top: "inception_a3_3x3_b2_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a3_3x3_b2_a_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a3_3x3_b2_a"
  top: "inception_a3_3x3_b2_a"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_3x3_b2_a_bn"
  type: "BatchNorm"
  bottom: "inception_a3_3x3_b2_a"
  top: "inception_a3_3x3_b2_a"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a3_3x3_b2_a_relu"
  type: "ReLU"
  bottom: "inception_a3_3x3_b2_a"
  top: "inception_a3_3x3_b2_a"
}
layer {
  name: "inception_a3_concat"
  type: "Concat"
  bottom: "inception_a3_1x1_b0"
  bottom: "inception_a3_3x3_b1"
  bottom: "inception_a3_3x3_b2_a"
  top: "inception_a3_concat"
}
layer {
  name: "inception_a3_1x1"
  type: "Convolution"
  bottom: "inception_a3_concat"
  top: "inception_a3_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_a3_scaled"
  type: "Power"
  bottom: "inception_a3_1x1"
  top: "inception_a3_scaled"
  power_param {
    power: 1.0
    scale: 0.170000001788
    shift: 0.0
  }
}
layer {
  name: "inception_a3_output"
  type: "Eltwise"
  bottom: "inception_a2_output"
  bottom: "inception_a3_scaled"
  top: "inception_a3_output"
}
layer {
  name: "inception_a3_output_relu"
  type: "ReLU"
  bottom: "inception_a3_output"
  top: "inception_a3_output"
}
layer {
  name: "inception_a4_1x1_b0"
  type: "Convolution"
  bottom: "inception_a3_output"
  top: "inception_a4_1x1_b0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a4_1x1_b0_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a4_1x1_b0"
  top: "inception_a4_1x1_b0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_1x1_b0_bn"
  type: "BatchNorm"
  bottom: "inception_a4_1x1_b0"
  top: "inception_a4_1x1_b0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_1x1_b0_relu"
  type: "ReLU"
  bottom: "inception_a4_1x1_b0"
  top: "inception_a4_1x1_b0"
}
layer {
  name: "inception_a4_1x1_b1"
  type: "Convolution"
  bottom: "inception_a3_output"
  top: "inception_a4_1x1_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a4_1x1_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a4_1x1_b1"
  top: "inception_a4_1x1_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_1x1_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a4_1x1_b1"
  top: "inception_a4_1x1_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_1x1_b1_relu"
  type: "ReLU"
  bottom: "inception_a4_1x1_b1"
  top: "inception_a4_1x1_b1"
}
layer {
  name: "inception_a4_3x3_b1"
  type: "Convolution"
  bottom: "inception_a4_1x1_b1"
  top: "inception_a4_3x3_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a4_3x3_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a4_3x3_b1"
  top: "inception_a4_3x3_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_3x3_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a4_3x3_b1"
  top: "inception_a4_3x3_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_3x3_b1_relu"
  type: "ReLU"
  bottom: "inception_a4_3x3_b1"
  top: "inception_a4_3x3_b1"
}
layer {
  name: "inception_a4_1x1_b2"
  type: "Convolution"
  bottom: "inception_a3_output"
  top: "inception_a4_1x1_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a4_1x1_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a4_1x1_b2"
  top: "inception_a4_1x1_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_1x1_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a4_1x1_b2"
  top: "inception_a4_1x1_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_1x1_b2_relu"
  type: "ReLU"
  bottom: "inception_a4_1x1_b2"
  top: "inception_a4_1x1_b2"
}
layer {
  name: "inception_a4_3x3_b2"
  type: "Convolution"
  bottom: "inception_a4_1x1_b2"
  top: "inception_a4_3x3_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a4_3x3_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a4_3x3_b2"
  top: "inception_a4_3x3_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_3x3_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a4_3x3_b2"
  top: "inception_a4_3x3_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_3x3_b2_relu"
  type: "ReLU"
  bottom: "inception_a4_3x3_b2"
  top: "inception_a4_3x3_b2"
}
layer {
  name: "inception_a4_3x3_b2_a"
  type: "Convolution"
  bottom: "inception_a4_3x3_b2"
  top: "inception_a4_3x3_b2_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a4_3x3_b2_a_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a4_3x3_b2_a"
  top: "inception_a4_3x3_b2_a"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_3x3_b2_a_bn"
  type: "BatchNorm"
  bottom: "inception_a4_3x3_b2_a"
  top: "inception_a4_3x3_b2_a"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a4_3x3_b2_a_relu"
  type: "ReLU"
  bottom: "inception_a4_3x3_b2_a"
  top: "inception_a4_3x3_b2_a"
}
layer {
  name: "inception_a4_concat"
  type: "Concat"
  bottom: "inception_a4_1x1_b0"
  bottom: "inception_a4_3x3_b1"
  bottom: "inception_a4_3x3_b2_a"
  top: "inception_a4_concat"
}
layer {
  name: "inception_a4_1x1"
  type: "Convolution"
  bottom: "inception_a4_concat"
  top: "inception_a4_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_a4_scaled"
  type: "Power"
  bottom: "inception_a4_1x1"
  top: "inception_a4_scaled"
  power_param {
    power: 1.0
    scale: 0.170000001788
    shift: 0.0
  }
}
layer {
  name: "inception_a4_output"
  type: "Eltwise"
  bottom: "inception_a3_output"
  bottom: "inception_a4_scaled"
  top: "inception_a4_output"
}
layer {
  name: "inception_a4_output_relu"
  type: "ReLU"
  bottom: "inception_a4_output"
  top: "inception_a4_output"
}
layer {
  name: "inception_a5_1x1_b0"
  type: "Convolution"
  bottom: "inception_a4_output"
  top: "inception_a5_1x1_b0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a5_1x1_b0_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a5_1x1_b0"
  top: "inception_a5_1x1_b0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_1x1_b0_bn"
  type: "BatchNorm"
  bottom: "inception_a5_1x1_b0"
  top: "inception_a5_1x1_b0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_1x1_b0_relu"
  type: "ReLU"
  bottom: "inception_a5_1x1_b0"
  top: "inception_a5_1x1_b0"
}
layer {
  name: "inception_a5_1x1_b1"
  type: "Convolution"
  bottom: "inception_a4_output"
  top: "inception_a5_1x1_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a5_1x1_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a5_1x1_b1"
  top: "inception_a5_1x1_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_1x1_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a5_1x1_b1"
  top: "inception_a5_1x1_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_1x1_b1_relu"
  type: "ReLU"
  bottom: "inception_a5_1x1_b1"
  top: "inception_a5_1x1_b1"
}
layer {
  name: "inception_a5_3x3_b1"
  type: "Convolution"
  bottom: "inception_a5_1x1_b1"
  top: "inception_a5_3x3_b1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a5_3x3_b1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a5_3x3_b1"
  top: "inception_a5_3x3_b1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_3x3_b1_bn"
  type: "BatchNorm"
  bottom: "inception_a5_3x3_b1"
  top: "inception_a5_3x3_b1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_3x3_b1_relu"
  type: "ReLU"
  bottom: "inception_a5_3x3_b1"
  top: "inception_a5_3x3_b1"
}
layer {
  name: "inception_a5_1x1_b2"
  type: "Convolution"
  bottom: "inception_a4_output"
  top: "inception_a5_1x1_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a5_1x1_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a5_1x1_b2"
  top: "inception_a5_1x1_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_1x1_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a5_1x1_b2"
  top: "inception_a5_1x1_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_1x1_b2_relu"
  type: "ReLU"
  bottom: "inception_a5_1x1_b2"
  top: "inception_a5_1x1_b2"
}
layer {
  name: "inception_a5_3x3_b2"
  type: "Convolution"
  bottom: "inception_a5_1x1_b2"
  top: "inception_a5_3x3_b2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a5_3x3_b2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a5_3x3_b2"
  top: "inception_a5_3x3_b2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_3x3_b2_bn"
  type: "BatchNorm"
  bottom: "inception_a5_3x3_b2"
  top: "inception_a5_3x3_b2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_3x3_b2_relu"
  type: "ReLU"
  bottom: "inception_a5_3x3_b2"
  top: "inception_a5_3x3_b2"
}
layer {
  name: "inception_a5_3x3_b2_a"
  type: "Convolution"
  bottom: "inception_a5_3x3_b2"
  top: "inception_a5_3x3_b2_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_a5_3x3_b2_a_bn_tr"
  type: "BatchNorm"
  bottom: "inception_a5_3x3_b2_a"
  top: "inception_a5_3x3_b2_a"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_3x3_b2_a_bn"
  type: "BatchNorm"
  bottom: "inception_a5_3x3_b2_a"
  top: "inception_a5_3x3_b2_a"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_a5_3x3_b2_a_relu"
  type: "ReLU"
  bottom: "inception_a5_3x3_b2_a"
  top: "inception_a5_3x3_b2_a"
}
layer {
  name: "inception_a5_concat"
  type: "Concat"
  bottom: "inception_a5_1x1_b0"
  bottom: "inception_a5_3x3_b1"
  bottom: "inception_a5_3x3_b2_a"
  top: "inception_a5_concat"
}
layer {
  name: "inception_a5_1x1"
  type: "Convolution"
  bottom: "inception_a5_concat"
  top: "inception_a5_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_a5_scaled"
  type: "Power"
  bottom: "inception_a5_1x1"
  top: "inception_a5_scaled"
  power_param {
    power: 1.0
    scale: 0.170000001788
    shift: 0.0
  }
}
layer {
  name: "inception_a5_output"
  type: "Eltwise"
  bottom: "inception_a4_output"
  bottom: "inception_a5_scaled"
  top: "inception_a5_output"
}
layer {
  name: "inception_a5_output_relu"
  type: "ReLU"
  bottom: "inception_a5_output"
  top: "inception_a5_output"
}
layer {
  name: "reduction_a_conv_3x3"
  type: "Convolution"
  bottom: "inception_a5_output"
  top: "reduction_a_conv_3x3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 384
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_a_conv_3x3_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_a_conv_3x3"
  top: "reduction_a_conv_3x3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_3x3_bn"
  type: "BatchNorm"
  bottom: "reduction_a_conv_3x3"
  top: "reduction_a_conv_3x3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_3x3_relu"
  type: "ReLU"
  bottom: "reduction_a_conv_3x3"
  top: "reduction_a_conv_3x3"
}
layer {
  name: "reduction_a_conv_1x1_reduce"
  type: "Convolution"
  bottom: "inception_a5_output"
  top: "reduction_a_conv_1x1_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_a_conv_1x1_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_a_conv_1x1_reduce"
  top: "reduction_a_conv_1x1_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_1x1_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_a_conv_1x1_reduce"
  top: "reduction_a_conv_1x1_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_1x1_reduce_relu"
  type: "ReLU"
  bottom: "reduction_a_conv_1x1_reduce"
  top: "reduction_a_conv_1x1_reduce"
}
layer {
  name: "reduction_a_conv_3x3_2"
  type: "Convolution"
  bottom: "reduction_a_conv_1x1_reduce"
  top: "reduction_a_conv_3x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_a_conv_3x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_a_conv_3x3_2"
  top: "reduction_a_conv_3x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_3x3_2_bn"
  type: "BatchNorm"
  bottom: "reduction_a_conv_3x3_2"
  top: "reduction_a_conv_3x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_3x3_2_relu"
  type: "ReLU"
  bottom: "reduction_a_conv_3x3_2"
  top: "reduction_a_conv_3x3_2"
}
layer {
  name: "reduction_a_conv_3x3_3"
  type: "Convolution"
  bottom: "reduction_a_conv_3x3_2"
  top: "reduction_a_conv_3x3_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_a_conv_3x3_3_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_a_conv_3x3_3"
  top: "reduction_a_conv_3x3_3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_3x3_3_bn"
  type: "BatchNorm"
  bottom: "reduction_a_conv_3x3_3"
  top: "reduction_a_conv_3x3_3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_a_conv_3x3_3_relu"
  type: "ReLU"
  bottom: "reduction_a_conv_3x3_3"
  top: "reduction_a_conv_3x3_3"
}
layer {
  name: "reduction_a_pool"
  type: "Pooling"
  bottom: "inception_a5_output"
  top: "reduction_a_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "reduction_a_concat"
  type: "Concat"
  bottom: "reduction_a_conv_3x3"
  bottom: "reduction_a_conv_3x3_3"
  bottom: "reduction_a_pool"
  top: "reduction_a_concat"
}
layer {
  name: "inception_b1_1x1"
  type: "Convolution"
  bottom: "reduction_a_concat"
  top: "inception_b1_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b1_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b1_1x1"
  top: "inception_b1_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b1_1x1"
  top: "inception_b1_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_1x1_relu"
  type: "ReLU"
  bottom: "inception_b1_1x1"
  top: "inception_b1_1x1"
}
layer {
  name: "inception_b1_1x7_2_reduce"
  type: "Convolution"
  bottom: "reduction_a_concat"
  top: "inception_b1_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b1_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b1_1x7_2_reduce"
  top: "inception_b1_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b1_1x7_2_reduce"
  top: "inception_b1_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b1_1x7_2_reduce"
  top: "inception_b1_1x7_2_reduce"
}
layer {
  name: "inception_b1_1x7_2"
  type: "Convolution"
  bottom: "inception_b1_1x7_2_reduce"
  top: "inception_b1_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b1_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b1_1x7_2"
  top: "inception_b1_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b1_1x7_2"
  top: "inception_b1_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b1_1x7_2"
  top: "inception_b1_1x7_2"
}
layer {
  name: "inception_b1_7x1_2"
  type: "Convolution"
  bottom: "inception_b1_1x7_2"
  top: "inception_b1_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b1_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b1_7x1_2"
  top: "inception_b1_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b1_7x1_2"
  top: "inception_b1_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b1_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b1_7x1_2"
  top: "inception_b1_7x1_2"
}
layer {
  name: "inception_b1_concat"
  type: "Concat"
  bottom: "inception_b1_1x1"
  bottom: "inception_b1_7x1_2"
  top: "inception_b1_concat"
}
layer {
  name: "inception_b1_1x1_a"
  type: "Convolution"
  bottom: "inception_b1_concat"
  top: "inception_b1_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b1_scaled"
  type: "Power"
  bottom: "inception_b1_1x1_a"
  top: "inception_b1_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b1_output"
  type: "Eltwise"
  bottom: "reduction_a_concat"
  bottom: "inception_b1_scaled"
  top: "inception_b1_output"
}
layer {
  name: "inception_b1_output_relu"
  type: "ReLU"
  bottom: "inception_b1_output"
  top: "inception_b1_output"
}
layer {
  name: "inception_b2_1x1"
  type: "Convolution"
  bottom: "inception_b1_output"
  top: "inception_b2_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b2_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b2_1x1"
  top: "inception_b2_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b2_1x1"
  top: "inception_b2_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_1x1_relu"
  type: "ReLU"
  bottom: "inception_b2_1x1"
  top: "inception_b2_1x1"
}
layer {
  name: "inception_b2_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b1_output"
  top: "inception_b2_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b2_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b2_1x7_2_reduce"
  top: "inception_b2_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b2_1x7_2_reduce"
  top: "inception_b2_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b2_1x7_2_reduce"
  top: "inception_b2_1x7_2_reduce"
}
layer {
  name: "inception_b2_1x7_2"
  type: "Convolution"
  bottom: "inception_b2_1x7_2_reduce"
  top: "inception_b2_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b2_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b2_1x7_2"
  top: "inception_b2_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b2_1x7_2"
  top: "inception_b2_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b2_1x7_2"
  top: "inception_b2_1x7_2"
}
layer {
  name: "inception_b2_7x1_2"
  type: "Convolution"
  bottom: "inception_b2_1x7_2"
  top: "inception_b2_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b2_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b2_7x1_2"
  top: "inception_b2_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b2_7x1_2"
  top: "inception_b2_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b2_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b2_7x1_2"
  top: "inception_b2_7x1_2"
}
layer {
  name: "inception_b2_concat"
  type: "Concat"
  bottom: "inception_b2_1x1"
  bottom: "inception_b2_7x1_2"
  top: "inception_b2_concat"
}
layer {
  name: "inception_b2_1x1_a"
  type: "Convolution"
  bottom: "inception_b2_concat"
  top: "inception_b2_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b2_scaled"
  type: "Power"
  bottom: "inception_b2_1x1_a"
  top: "inception_b2_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b2_output"
  type: "Eltwise"
  bottom: "inception_b1_output"
  bottom: "inception_b2_scaled"
  top: "inception_b2_output"
}
layer {
  name: "inception_b2_output_relu"
  type: "ReLU"
  bottom: "inception_b2_output"
  top: "inception_b2_output"
}
layer {
  name: "inception_b3_1x1"
  type: "Convolution"
  bottom: "inception_b2_output"
  top: "inception_b3_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b3_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b3_1x1"
  top: "inception_b3_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b3_1x1"
  top: "inception_b3_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_1x1_relu"
  type: "ReLU"
  bottom: "inception_b3_1x1"
  top: "inception_b3_1x1"
}
layer {
  name: "inception_b3_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b2_output"
  top: "inception_b3_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b3_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b3_1x7_2_reduce"
  top: "inception_b3_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b3_1x7_2_reduce"
  top: "inception_b3_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b3_1x7_2_reduce"
  top: "inception_b3_1x7_2_reduce"
}
layer {
  name: "inception_b3_1x7_2"
  type: "Convolution"
  bottom: "inception_b3_1x7_2_reduce"
  top: "inception_b3_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b3_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b3_1x7_2"
  top: "inception_b3_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b3_1x7_2"
  top: "inception_b3_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b3_1x7_2"
  top: "inception_b3_1x7_2"
}
layer {
  name: "inception_b3_7x1_2"
  type: "Convolution"
  bottom: "inception_b3_1x7_2"
  top: "inception_b3_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b3_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b3_7x1_2"
  top: "inception_b3_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b3_7x1_2"
  top: "inception_b3_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b3_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b3_7x1_2"
  top: "inception_b3_7x1_2"
}
layer {
  name: "inception_b3_concat"
  type: "Concat"
  bottom: "inception_b3_1x1"
  bottom: "inception_b3_7x1_2"
  top: "inception_b3_concat"
}
layer {
  name: "inception_b3_1x1_a"
  type: "Convolution"
  bottom: "inception_b3_concat"
  top: "inception_b3_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b3_scaled"
  type: "Power"
  bottom: "inception_b3_1x1_a"
  top: "inception_b3_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b3_output"
  type: "Eltwise"
  bottom: "inception_b2_output"
  bottom: "inception_b3_scaled"
  top: "inception_b3_output"
}
layer {
  name: "inception_b3_output_relu"
  type: "ReLU"
  bottom: "inception_b3_output"
  top: "inception_b3_output"
}
layer {
  name: "inception_b4_1x1"
  type: "Convolution"
  bottom: "inception_b3_output"
  top: "inception_b4_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b4_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b4_1x1"
  top: "inception_b4_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b4_1x1"
  top: "inception_b4_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_1x1_relu"
  type: "ReLU"
  bottom: "inception_b4_1x1"
  top: "inception_b4_1x1"
}
layer {
  name: "inception_b4_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b3_output"
  top: "inception_b4_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b4_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b4_1x7_2_reduce"
  top: "inception_b4_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b4_1x7_2_reduce"
  top: "inception_b4_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b4_1x7_2_reduce"
  top: "inception_b4_1x7_2_reduce"
}
layer {
  name: "inception_b4_1x7_2"
  type: "Convolution"
  bottom: "inception_b4_1x7_2_reduce"
  top: "inception_b4_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b4_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b4_1x7_2"
  top: "inception_b4_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b4_1x7_2"
  top: "inception_b4_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b4_1x7_2"
  top: "inception_b4_1x7_2"
}
layer {
  name: "inception_b4_7x1_2"
  type: "Convolution"
  bottom: "inception_b4_1x7_2"
  top: "inception_b4_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b4_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b4_7x1_2"
  top: "inception_b4_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b4_7x1_2"
  top: "inception_b4_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b4_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b4_7x1_2"
  top: "inception_b4_7x1_2"
}
layer {
  name: "inception_b4_concat"
  type: "Concat"
  bottom: "inception_b4_1x1"
  bottom: "inception_b4_7x1_2"
  top: "inception_b4_concat"
}
layer {
  name: "inception_b4_1x1_a"
  type: "Convolution"
  bottom: "inception_b4_concat"
  top: "inception_b4_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b4_scaled"
  type: "Power"
  bottom: "inception_b4_1x1_a"
  top: "inception_b4_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b4_output"
  type: "Eltwise"
  bottom: "inception_b3_output"
  bottom: "inception_b4_scaled"
  top: "inception_b4_output"
}
layer {
  name: "inception_b4_output_relu"
  type: "ReLU"
  bottom: "inception_b4_output"
  top: "inception_b4_output"
}
layer {
  name: "inception_b5_1x1"
  type: "Convolution"
  bottom: "inception_b4_output"
  top: "inception_b5_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b5_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b5_1x1"
  top: "inception_b5_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b5_1x1"
  top: "inception_b5_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_1x1_relu"
  type: "ReLU"
  bottom: "inception_b5_1x1"
  top: "inception_b5_1x1"
}
layer {
  name: "inception_b5_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b4_output"
  top: "inception_b5_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b5_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b5_1x7_2_reduce"
  top: "inception_b5_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b5_1x7_2_reduce"
  top: "inception_b5_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b5_1x7_2_reduce"
  top: "inception_b5_1x7_2_reduce"
}
layer {
  name: "inception_b5_1x7_2"
  type: "Convolution"
  bottom: "inception_b5_1x7_2_reduce"
  top: "inception_b5_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b5_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b5_1x7_2"
  top: "inception_b5_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b5_1x7_2"
  top: "inception_b5_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b5_1x7_2"
  top: "inception_b5_1x7_2"
}
layer {
  name: "inception_b5_7x1_2"
  type: "Convolution"
  bottom: "inception_b5_1x7_2"
  top: "inception_b5_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b5_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b5_7x1_2"
  top: "inception_b5_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b5_7x1_2"
  top: "inception_b5_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b5_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b5_7x1_2"
  top: "inception_b5_7x1_2"
}
layer {
  name: "inception_b5_concat"
  type: "Concat"
  bottom: "inception_b5_1x1"
  bottom: "inception_b5_7x1_2"
  top: "inception_b5_concat"
}
layer {
  name: "inception_b5_1x1_a"
  type: "Convolution"
  bottom: "inception_b5_concat"
  top: "inception_b5_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b5_scaled"
  type: "Power"
  bottom: "inception_b5_1x1_a"
  top: "inception_b5_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b5_output"
  type: "Eltwise"
  bottom: "inception_b4_output"
  bottom: "inception_b5_scaled"
  top: "inception_b5_output"
}
layer {
  name: "inception_b5_output_relu"
  type: "ReLU"
  bottom: "inception_b5_output"
  top: "inception_b5_output"
}
layer {
  name: "inception_b6_1x1"
  type: "Convolution"
  bottom: "inception_b5_output"
  top: "inception_b6_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b6_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b6_1x1"
  top: "inception_b6_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b6_1x1"
  top: "inception_b6_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_1x1_relu"
  type: "ReLU"
  bottom: "inception_b6_1x1"
  top: "inception_b6_1x1"
}
layer {
  name: "inception_b6_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b5_output"
  top: "inception_b6_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b6_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b6_1x7_2_reduce"
  top: "inception_b6_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b6_1x7_2_reduce"
  top: "inception_b6_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b6_1x7_2_reduce"
  top: "inception_b6_1x7_2_reduce"
}
layer {
  name: "inception_b6_1x7_2"
  type: "Convolution"
  bottom: "inception_b6_1x7_2_reduce"
  top: "inception_b6_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b6_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b6_1x7_2"
  top: "inception_b6_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b6_1x7_2"
  top: "inception_b6_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b6_1x7_2"
  top: "inception_b6_1x7_2"
}
layer {
  name: "inception_b6_7x1_2"
  type: "Convolution"
  bottom: "inception_b6_1x7_2"
  top: "inception_b6_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b6_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b6_7x1_2"
  top: "inception_b6_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b6_7x1_2"
  top: "inception_b6_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b6_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b6_7x1_2"
  top: "inception_b6_7x1_2"
}
layer {
  name: "inception_b6_concat"
  type: "Concat"
  bottom: "inception_b6_1x1"
  bottom: "inception_b6_7x1_2"
  top: "inception_b6_concat"
}
layer {
  name: "inception_b6_1x1_a"
  type: "Convolution"
  bottom: "inception_b6_concat"
  top: "inception_b6_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b6_scaled"
  type: "Power"
  bottom: "inception_b6_1x1_a"
  top: "inception_b6_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b6_output"
  type: "Eltwise"
  bottom: "inception_b5_output"
  bottom: "inception_b6_scaled"
  top: "inception_b6_output"
}
layer {
  name: "inception_b6_output_relu"
  type: "ReLU"
  bottom: "inception_b6_output"
  top: "inception_b6_output"
}
layer {
  name: "inception_b7_1x1"
  type: "Convolution"
  bottom: "inception_b6_output"
  top: "inception_b7_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b7_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b7_1x1"
  top: "inception_b7_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b7_1x1"
  top: "inception_b7_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_1x1_relu"
  type: "ReLU"
  bottom: "inception_b7_1x1"
  top: "inception_b7_1x1"
}
layer {
  name: "inception_b7_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b6_output"
  top: "inception_b7_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b7_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b7_1x7_2_reduce"
  top: "inception_b7_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b7_1x7_2_reduce"
  top: "inception_b7_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b7_1x7_2_reduce"
  top: "inception_b7_1x7_2_reduce"
}
layer {
  name: "inception_b7_1x7_2"
  type: "Convolution"
  bottom: "inception_b7_1x7_2_reduce"
  top: "inception_b7_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b7_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b7_1x7_2"
  top: "inception_b7_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b7_1x7_2"
  top: "inception_b7_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b7_1x7_2"
  top: "inception_b7_1x7_2"
}
layer {
  name: "inception_b7_7x1_2"
  type: "Convolution"
  bottom: "inception_b7_1x7_2"
  top: "inception_b7_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b7_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b7_7x1_2"
  top: "inception_b7_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b7_7x1_2"
  top: "inception_b7_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b7_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b7_7x1_2"
  top: "inception_b7_7x1_2"
}
layer {
  name: "inception_b7_concat"
  type: "Concat"
  bottom: "inception_b7_1x1"
  bottom: "inception_b7_7x1_2"
  top: "inception_b7_concat"
}
layer {
  name: "inception_b7_1x1_a"
  type: "Convolution"
  bottom: "inception_b7_concat"
  top: "inception_b7_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b7_scaled"
  type: "Power"
  bottom: "inception_b7_1x1_a"
  top: "inception_b7_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b7_output"
  type: "Eltwise"
  bottom: "inception_b6_output"
  bottom: "inception_b7_scaled"
  top: "inception_b7_output"
}
layer {
  name: "inception_b7_output_relu"
  type: "ReLU"
  bottom: "inception_b7_output"
  top: "inception_b7_output"
}
layer {
  name: "inception_b8_1x1"
  type: "Convolution"
  bottom: "inception_b7_output"
  top: "inception_b8_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b8_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b8_1x1"
  top: "inception_b8_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b8_1x1"
  top: "inception_b8_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_1x1_relu"
  type: "ReLU"
  bottom: "inception_b8_1x1"
  top: "inception_b8_1x1"
}
layer {
  name: "inception_b8_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b7_output"
  top: "inception_b8_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b8_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b8_1x7_2_reduce"
  top: "inception_b8_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b8_1x7_2_reduce"
  top: "inception_b8_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b8_1x7_2_reduce"
  top: "inception_b8_1x7_2_reduce"
}
layer {
  name: "inception_b8_1x7_2"
  type: "Convolution"
  bottom: "inception_b8_1x7_2_reduce"
  top: "inception_b8_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b8_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b8_1x7_2"
  top: "inception_b8_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b8_1x7_2"
  top: "inception_b8_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b8_1x7_2"
  top: "inception_b8_1x7_2"
}
layer {
  name: "inception_b8_7x1_2"
  type: "Convolution"
  bottom: "inception_b8_1x7_2"
  top: "inception_b8_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b8_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b8_7x1_2"
  top: "inception_b8_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b8_7x1_2"
  top: "inception_b8_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b8_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b8_7x1_2"
  top: "inception_b8_7x1_2"
}
layer {
  name: "inception_b8_concat"
  type: "Concat"
  bottom: "inception_b8_1x1"
  bottom: "inception_b8_7x1_2"
  top: "inception_b8_concat"
}
layer {
  name: "inception_b8_1x1_a"
  type: "Convolution"
  bottom: "inception_b8_concat"
  top: "inception_b8_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b8_scaled"
  type: "Power"
  bottom: "inception_b8_1x1_a"
  top: "inception_b8_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b8_output"
  type: "Eltwise"
  bottom: "inception_b7_output"
  bottom: "inception_b8_scaled"
  top: "inception_b8_output"
}
layer {
  name: "inception_b8_output_relu"
  type: "ReLU"
  bottom: "inception_b8_output"
  top: "inception_b8_output"
}
layer {
  name: "inception_b9_1x1"
  type: "Convolution"
  bottom: "inception_b8_output"
  top: "inception_b9_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b9_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b9_1x1"
  top: "inception_b9_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b9_1x1"
  top: "inception_b9_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_1x1_relu"
  type: "ReLU"
  bottom: "inception_b9_1x1"
  top: "inception_b9_1x1"
}
layer {
  name: "inception_b9_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b8_output"
  top: "inception_b9_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b9_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b9_1x7_2_reduce"
  top: "inception_b9_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b9_1x7_2_reduce"
  top: "inception_b9_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b9_1x7_2_reduce"
  top: "inception_b9_1x7_2_reduce"
}
layer {
  name: "inception_b9_1x7_2"
  type: "Convolution"
  bottom: "inception_b9_1x7_2_reduce"
  top: "inception_b9_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b9_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b9_1x7_2"
  top: "inception_b9_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b9_1x7_2"
  top: "inception_b9_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b9_1x7_2"
  top: "inception_b9_1x7_2"
}
layer {
  name: "inception_b9_7x1_2"
  type: "Convolution"
  bottom: "inception_b9_1x7_2"
  top: "inception_b9_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b9_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b9_7x1_2"
  top: "inception_b9_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b9_7x1_2"
  top: "inception_b9_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b9_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b9_7x1_2"
  top: "inception_b9_7x1_2"
}
layer {
  name: "inception_b9_concat"
  type: "Concat"
  bottom: "inception_b9_1x1"
  bottom: "inception_b9_7x1_2"
  top: "inception_b9_concat"
}
layer {
  name: "inception_b9_1x1_a"
  type: "Convolution"
  bottom: "inception_b9_concat"
  top: "inception_b9_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b9_scaled"
  type: "Power"
  bottom: "inception_b9_1x1_a"
  top: "inception_b9_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b9_output"
  type: "Eltwise"
  bottom: "inception_b8_output"
  bottom: "inception_b9_scaled"
  top: "inception_b9_output"
}
layer {
  name: "inception_b9_output_relu"
  type: "ReLU"
  bottom: "inception_b9_output"
  top: "inception_b9_output"
}
layer {
  name: "inception_b10_1x1"
  type: "Convolution"
  bottom: "inception_b9_output"
  top: "inception_b10_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b10_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b10_1x1"
  top: "inception_b10_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_b10_1x1"
  top: "inception_b10_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_1x1_relu"
  type: "ReLU"
  bottom: "inception_b10_1x1"
  top: "inception_b10_1x1"
}
layer {
  name: "inception_b10_1x7_2_reduce"
  type: "Convolution"
  bottom: "inception_b9_output"
  top: "inception_b10_1x7_2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_b10_1x7_2_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b10_1x7_2_reduce"
  top: "inception_b10_1x7_2_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_1x7_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_b10_1x7_2_reduce"
  top: "inception_b10_1x7_2_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_1x7_2_reduce_relu"
  type: "ReLU"
  bottom: "inception_b10_1x7_2_reduce"
  top: "inception_b10_1x7_2_reduce"
}
layer {
  name: "inception_b10_1x7_2"
  type: "Convolution"
  bottom: "inception_b10_1x7_2_reduce"
  top: "inception_b10_1x7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_b10_1x7_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b10_1x7_2"
  top: "inception_b10_1x7_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_1x7_2_bn"
  type: "BatchNorm"
  bottom: "inception_b10_1x7_2"
  top: "inception_b10_1x7_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_1x7_2_relu"
  type: "ReLU"
  bottom: "inception_b10_1x7_2"
  top: "inception_b10_1x7_2"
}
layer {
  name: "inception_b10_7x1_2"
  type: "Convolution"
  bottom: "inception_b10_1x7_2"
  top: "inception_b10_7x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_b10_7x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_b10_7x1_2"
  top: "inception_b10_7x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_7x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_b10_7x1_2"
  top: "inception_b10_7x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_b10_7x1_2_relu"
  type: "ReLU"
  bottom: "inception_b10_7x1_2"
  top: "inception_b10_7x1_2"
}
layer {
  name: "inception_b10_concat"
  type: "Concat"
  bottom: "inception_b10_1x1"
  bottom: "inception_b10_7x1_2"
  top: "inception_b10_concat"
}
layer {
  name: "inception_b10_1x1_a"
  type: "Convolution"
  bottom: "inception_b10_concat"
  top: "inception_b10_1x1_a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 896
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_b10_scaled"
  type: "Power"
  bottom: "inception_b10_1x1_a"
  top: "inception_b10_scaled"
  power_param {
    power: 1.0
    scale: 0.10000000149
    shift: 0.0
  }
}
layer {
  name: "inception_b10_output"
  type: "Eltwise"
  bottom: "inception_b9_output"
  bottom: "inception_b10_scaled"
  top: "inception_b10_output"
}
layer {
  name: "inception_b10_output_relu"
  type: "ReLU"
  bottom: "inception_b10_output"
  top: "inception_b10_output"
}
layer {
  name: "reduction_b_pool"
  type: "Pooling"
  bottom: "inception_b10_output"
  top: "reduction_b_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "reduction_b_3x3_reduce"
  type: "Convolution"
  bottom: "inception_b10_output"
  top: "reduction_b_3x3_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_reduce_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_reduce_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
}
layer {
  name: "reduction_b_3x3"
  type: "Convolution"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 384
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
}
layer {
  name: "reduction_b_3x3_reduce_1"
  type: "Convolution"
  bottom: "inception_b10_output"
  top: "reduction_b_3x3_reduce_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_reduce_1_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce_1"
  top: "reduction_b_3x3_reduce_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_reduce_1_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce_1"
  top: "reduction_b_3x3_reduce_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_reduce_1_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_reduce_1"
  top: "reduction_b_3x3_reduce_1"
}
layer {
  name: "reduction_b_3x3_1"
  type: "Convolution"
  bottom: "reduction_b_3x3_reduce_1"
  top: "reduction_b_3x3_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_1_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_1"
  top: "reduction_b_3x3_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_1_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_1"
  top: "reduction_b_3x3_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_1_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_1"
  top: "reduction_b_3x3_1"
}
layer {
  name: "reduction_b_3x3_reduce_2"
  type: "Convolution"
  bottom: "inception_b10_output"
  top: "reduction_b_3x3_reduce_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_reduce_2_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce_2"
  top: "reduction_b_3x3_reduce_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_reduce_2_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce_2"
  top: "reduction_b_3x3_reduce_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_reduce_2_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_reduce_2"
  top: "reduction_b_3x3_reduce_2"
}
layer {
  name: "reduction_b_3x3_2"
  type: "Convolution"
  bottom: "reduction_b_3x3_reduce_2"
  top: "reduction_b_3x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_2_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_2_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
}
layer {
  name: "reduction_b_3x3_2a"
  type: "Convolution"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2a"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "reduction_b_3x3_2a_bn_tr"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2a"
  top: "reduction_b_3x3_2a"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_2a_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2a"
  top: "reduction_b_3x3_2a"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "reduction_b_3x3_2a_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_2a"
  top: "reduction_b_3x3_2a"
}
layer {
  name: "reduction_b_concat"
  type: "Concat"
  bottom: "reduction_b_3x3"
  bottom: "reduction_b_3x3_1"
  bottom: "reduction_b_3x3_2a"
  bottom: "reduction_b_pool"
  top: "reduction_b_concat"
}
layer {
  name: "inception_c1_1x1"
  type: "Convolution"
  bottom: "reduction_b_concat"
  top: "inception_c1_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c1_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c1_1x1"
  top: "inception_c1_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_c1_1x1"
  top: "inception_c1_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_1x1_relu"
  type: "ReLU"
  bottom: "inception_c1_1x1"
  top: "inception_c1_1x1"
}
layer {
  name: "inception_c1_1x1_2"
  type: "Convolution"
  bottom: "reduction_b_concat"
  top: "inception_c1_1x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c1_1x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c1_1x1_2"
  top: "inception_c1_1x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_1x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c1_1x1_2"
  top: "inception_c1_1x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_1x1_2_relu"
  type: "ReLU"
  bottom: "inception_c1_1x1_2"
  top: "inception_c1_1x1_2"
}
layer {
  name: "inception_c1_1x3_2"
  type: "Convolution"
  bottom: "inception_c1_1x1_2"
  top: "inception_c1_1x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "inception_c1_1x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c1_1x3_2"
  top: "inception_c1_1x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_1x3_2_bn"
  type: "BatchNorm"
  bottom: "inception_c1_1x3_2"
  top: "inception_c1_1x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_1x3_2_relu"
  type: "ReLU"
  bottom: "inception_c1_1x3_2"
  top: "inception_c1_1x3_2"
}
layer {
  name: "inception_c1_3x1_2"
  type: "Convolution"
  bottom: "inception_c1_1x3_2"
  top: "inception_c1_3x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "inception_c1_3x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c1_3x1_2"
  top: "inception_c1_3x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_3x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c1_3x1_2"
  top: "inception_c1_3x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c1_3x1_2_relu"
  type: "ReLU"
  bottom: "inception_c1_3x1_2"
  top: "inception_c1_3x1_2"
}
layer {
  name: "inception_c1_concat"
  type: "Concat"
  bottom: "inception_c1_1x1"
  bottom: "inception_c1_3x1_2"
  top: "inception_c1_concat"
}
layer {
  name: "inception_c1_1x1_3"
  type: "Convolution"
  bottom: "inception_c1_concat"
  top: "inception_c1_1x1_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1792
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_c1_scaled"
  type: "Power"
  bottom: "inception_c1_1x1_3"
  top: "inception_c1_scaled"
  power_param {
    power: 1.0
    scale: 0.20000000298
    shift: 0.0
  }
}
layer {
  name: "inception_c1_output"
  type: "Eltwise"
  bottom: "reduction_b_concat"
  bottom: "inception_c1_scaled"
  top: "inception_c1_output"
}
layer {
  name: "inception_c1_output_relu"
  type: "ReLU"
  bottom: "inception_c1_output"
  top: "inception_c1_output"
}
layer {
  name: "inception_c2_1x1"
  type: "Convolution"
  bottom: "inception_c1_output"
  top: "inception_c2_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c2_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c2_1x1"
  top: "inception_c2_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_c2_1x1"
  top: "inception_c2_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_1x1_relu"
  type: "ReLU"
  bottom: "inception_c2_1x1"
  top: "inception_c2_1x1"
}
layer {
  name: "inception_c2_1x1_2"
  type: "Convolution"
  bottom: "inception_c1_output"
  top: "inception_c2_1x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c2_1x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c2_1x1_2"
  top: "inception_c2_1x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_1x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c2_1x1_2"
  top: "inception_c2_1x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_1x1_2_relu"
  type: "ReLU"
  bottom: "inception_c2_1x1_2"
  top: "inception_c2_1x1_2"
}
layer {
  name: "inception_c2_1x3_2"
  type: "Convolution"
  bottom: "inception_c2_1x1_2"
  top: "inception_c2_1x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "inception_c2_1x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c2_1x3_2"
  top: "inception_c2_1x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_1x3_2_bn"
  type: "BatchNorm"
  bottom: "inception_c2_1x3_2"
  top: "inception_c2_1x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_1x3_2_relu"
  type: "ReLU"
  bottom: "inception_c2_1x3_2"
  top: "inception_c2_1x3_2"
}
layer {
  name: "inception_c2_3x1_2"
  type: "Convolution"
  bottom: "inception_c2_1x3_2"
  top: "inception_c2_3x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "inception_c2_3x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c2_3x1_2"
  top: "inception_c2_3x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_3x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c2_3x1_2"
  top: "inception_c2_3x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c2_3x1_2_relu"
  type: "ReLU"
  bottom: "inception_c2_3x1_2"
  top: "inception_c2_3x1_2"
}
layer {
  name: "inception_c2_concat"
  type: "Concat"
  bottom: "inception_c2_1x1"
  bottom: "inception_c2_3x1_2"
  top: "inception_c2_concat"
}
layer {
  name: "inception_c2_1x1_3"
  type: "Convolution"
  bottom: "inception_c2_concat"
  top: "inception_c2_1x1_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1792
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_c2_scaled"
  type: "Power"
  bottom: "inception_c2_1x1_3"
  top: "inception_c2_scaled"
  power_param {
    power: 1.0
    scale: 0.20000000298
    shift: 0.0
  }
}
layer {
  name: "inception_c2_output"
  type: "Eltwise"
  bottom: "inception_c1_output"
  bottom: "inception_c2_scaled"
  top: "inception_c2_output"
}
layer {
  name: "inception_c2_output_relu"
  type: "ReLU"
  bottom: "inception_c2_output"
  top: "inception_c2_output"
}
layer {
  name: "inception_c3_1x1"
  type: "Convolution"
  bottom: "inception_c2_output"
  top: "inception_c3_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c3_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c3_1x1"
  top: "inception_c3_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_c3_1x1"
  top: "inception_c3_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_1x1_relu"
  type: "ReLU"
  bottom: "inception_c3_1x1"
  top: "inception_c3_1x1"
}
layer {
  name: "inception_c3_1x1_2"
  type: "Convolution"
  bottom: "inception_c2_output"
  top: "inception_c3_1x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c3_1x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c3_1x1_2"
  top: "inception_c3_1x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_1x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c3_1x1_2"
  top: "inception_c3_1x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_1x1_2_relu"
  type: "ReLU"
  bottom: "inception_c3_1x1_2"
  top: "inception_c3_1x1_2"
}
layer {
  name: "inception_c3_1x3_2"
  type: "Convolution"
  bottom: "inception_c3_1x1_2"
  top: "inception_c3_1x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "inception_c3_1x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c3_1x3_2"
  top: "inception_c3_1x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_1x3_2_bn"
  type: "BatchNorm"
  bottom: "inception_c3_1x3_2"
  top: "inception_c3_1x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_1x3_2_relu"
  type: "ReLU"
  bottom: "inception_c3_1x3_2"
  top: "inception_c3_1x3_2"
}
layer {
  name: "inception_c3_3x1_2"
  type: "Convolution"
  bottom: "inception_c3_1x3_2"
  top: "inception_c3_3x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "inception_c3_3x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c3_3x1_2"
  top: "inception_c3_3x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_3x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c3_3x1_2"
  top: "inception_c3_3x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c3_3x1_2_relu"
  type: "ReLU"
  bottom: "inception_c3_3x1_2"
  top: "inception_c3_3x1_2"
}
layer {
  name: "inception_c3_concat"
  type: "Concat"
  bottom: "inception_c3_1x1"
  bottom: "inception_c3_3x1_2"
  top: "inception_c3_concat"
}
layer {
  name: "inception_c3_1x1_3"
  type: "Convolution"
  bottom: "inception_c3_concat"
  top: "inception_c3_1x1_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1792
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_c3_scaled"
  type: "Power"
  bottom: "inception_c3_1x1_3"
  top: "inception_c3_scaled"
  power_param {
    power: 1.0
    scale: 0.20000000298
    shift: 0.0
  }
}
layer {
  name: "inception_c3_output"
  type: "Eltwise"
  bottom: "inception_c2_output"
  bottom: "inception_c3_scaled"
  top: "inception_c3_output"
}
layer {
  name: "inception_c3_output_relu"
  type: "ReLU"
  bottom: "inception_c3_output"
  top: "inception_c3_output"
}
layer {
  name: "inception_c4_1x1"
  type: "Convolution"
  bottom: "inception_c3_output"
  top: "inception_c4_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c4_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c4_1x1"
  top: "inception_c4_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_c4_1x1"
  top: "inception_c4_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_1x1_relu"
  type: "ReLU"
  bottom: "inception_c4_1x1"
  top: "inception_c4_1x1"
}
layer {
  name: "inception_c4_1x1_2"
  type: "Convolution"
  bottom: "inception_c3_output"
  top: "inception_c4_1x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c4_1x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c4_1x1_2"
  top: "inception_c4_1x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_1x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c4_1x1_2"
  top: "inception_c4_1x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_1x1_2_relu"
  type: "ReLU"
  bottom: "inception_c4_1x1_2"
  top: "inception_c4_1x1_2"
}
layer {
  name: "inception_c4_1x3_2"
  type: "Convolution"
  bottom: "inception_c4_1x1_2"
  top: "inception_c4_1x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "inception_c4_1x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c4_1x3_2"
  top: "inception_c4_1x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_1x3_2_bn"
  type: "BatchNorm"
  bottom: "inception_c4_1x3_2"
  top: "inception_c4_1x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_1x3_2_relu"
  type: "ReLU"
  bottom: "inception_c4_1x3_2"
  top: "inception_c4_1x3_2"
}
layer {
  name: "inception_c4_3x1_2"
  type: "Convolution"
  bottom: "inception_c4_1x3_2"
  top: "inception_c4_3x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "inception_c4_3x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c4_3x1_2"
  top: "inception_c4_3x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_3x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c4_3x1_2"
  top: "inception_c4_3x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c4_3x1_2_relu"
  type: "ReLU"
  bottom: "inception_c4_3x1_2"
  top: "inception_c4_3x1_2"
}
layer {
  name: "inception_c4_concat"
  type: "Concat"
  bottom: "inception_c4_1x1"
  bottom: "inception_c4_3x1_2"
  top: "inception_c4_concat"
}
layer {
  name: "inception_c4_1x1_3"
  type: "Convolution"
  bottom: "inception_c4_concat"
  top: "inception_c4_1x1_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1792
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_c4_scaled"
  type: "Power"
  bottom: "inception_c4_1x1_3"
  top: "inception_c4_scaled"
  power_param {
    power: 1.0
    scale: 0.20000000298
    shift: 0.0
  }
}
layer {
  name: "inception_c4_output"
  type: "Eltwise"
  bottom: "inception_c3_output"
  bottom: "inception_c4_scaled"
  top: "inception_c4_output"
}
layer {
  name: "inception_c4_output_relu"
  type: "ReLU"
  bottom: "inception_c4_output"
  top: "inception_c4_output"
}
layer {
  name: "inception_c5_1x1"
  type: "Convolution"
  bottom: "inception_c4_output"
  top: "inception_c5_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c5_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c5_1x1"
  top: "inception_c5_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_c5_1x1"
  top: "inception_c5_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_1x1_relu"
  type: "ReLU"
  bottom: "inception_c5_1x1"
  top: "inception_c5_1x1"
}
layer {
  name: "inception_c5_1x1_2"
  type: "Convolution"
  bottom: "inception_c4_output"
  top: "inception_c5_1x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "inception_c5_1x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c5_1x1_2"
  top: "inception_c5_1x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_1x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c5_1x1_2"
  top: "inception_c5_1x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_1x1_2_relu"
  type: "ReLU"
  bottom: "inception_c5_1x1_2"
  top: "inception_c5_1x1_2"
}
layer {
  name: "inception_c5_1x3_2"
  type: "Convolution"
  bottom: "inception_c5_1x1_2"
  top: "inception_c5_1x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "inception_c5_1x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c5_1x3_2"
  top: "inception_c5_1x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_1x3_2_bn"
  type: "BatchNorm"
  bottom: "inception_c5_1x3_2"
  top: "inception_c5_1x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_1x3_2_relu"
  type: "ReLU"
  bottom: "inception_c5_1x3_2"
  top: "inception_c5_1x3_2"
}
layer {
  name: "inception_c5_3x1_2"
  type: "Convolution"
  bottom: "inception_c5_1x3_2"
  top: "inception_c5_3x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "inception_c5_3x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "inception_c5_3x1_2"
  top: "inception_c5_3x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_3x1_2_bn"
  type: "BatchNorm"
  bottom: "inception_c5_3x1_2"
  top: "inception_c5_3x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "inception_c5_3x1_2_relu"
  type: "ReLU"
  bottom: "inception_c5_3x1_2"
  top: "inception_c5_3x1_2"
}
layer {
  name: "inception_c5_concat"
  type: "Concat"
  bottom: "inception_c5_1x1"
  bottom: "inception_c5_3x1_2"
  top: "inception_c5_concat"
}
layer {
  name: "inception_c5_1x1_3"
  type: "Convolution"
  bottom: "inception_c5_concat"
  top: "inception_c5_1x1_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1792
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "inception_c5_scaled"
  type: "Power"
  bottom: "inception_c5_1x1_3"
  top: "inception_c5_scaled"
  power_param {
    power: 1.0
    scale: 0.20000000298
    shift: 0.0
  }
}
layer {
  name: "inception_c5_output"
  type: "Eltwise"
  bottom: "inception_c4_output"
  bottom: "inception_c5_scaled"
  top: "inception_c5_output"
}
layer {
  name: "inception_c5_output_relu"
  type: "ReLU"
  bottom: "inception_c5_output"
  top: "inception_c5_output"
}
layer {
  name: "Block8_conv_1x1"
  type: "Convolution"
  bottom: "inception_c5_output"
  top: "Block8_conv_1x1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "Block8_conv_1x1_bn_tr"
  type: "BatchNorm"
  bottom: "Block8_conv_1x1"
  top: "Block8_conv_1x1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_1x1_bn"
  type: "BatchNorm"
  bottom: "Block8_conv_1x1"
  top: "Block8_conv_1x1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_1x1_relu"
  type: "ReLU"
  bottom: "Block8_conv_1x1"
  top: "Block8_conv_1x1"
}
layer {
  name: "Block8_conv_1x1_2"
  type: "Convolution"
  bottom: "inception_c5_output"
  top: "Block8_conv_1x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
  }
}
layer {
  name: "Block8_conv_1x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "Block8_conv_1x1_2"
  top: "Block8_conv_1x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_1x1_2_bn"
  type: "BatchNorm"
  bottom: "Block8_conv_1x1_2"
  top: "Block8_conv_1x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_1x1_2_relu"
  type: "ReLU"
  bottom: "Block8_conv_1x1_2"
  top: "Block8_conv_1x1_2"
}
layer {
  name: "Block8_conv_1x3_2"
  type: "Convolution"
  bottom: "Block8_conv_1x1_2"
  top: "Block8_conv_1x3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "Block8_conv_1x3_2_bn_tr"
  type: "BatchNorm"
  bottom: "Block8_conv_1x3_2"
  top: "Block8_conv_1x3_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_1x3_2_bn"
  type: "BatchNorm"
  bottom: "Block8_conv_1x3_2"
  top: "Block8_conv_1x3_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_1x3_2_relu"
  type: "ReLU"
  bottom: "Block8_conv_1x3_2"
  top: "Block8_conv_1x3_2"
}
layer {
  name: "Block8_conv_3x1_2"
  type: "Convolution"
  bottom: "Block8_conv_1x3_2"
  top: "Block8_conv_3x1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "Block8_conv_3x1_2_bn_tr"
  type: "BatchNorm"
  bottom: "Block8_conv_3x1_2"
  top: "Block8_conv_3x1_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_3x1_2_bn"
  type: "BatchNorm"
  bottom: "Block8_conv_3x1_2"
  top: "Block8_conv_3x1_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Block8_conv_3x1_2_relu"
  type: "ReLU"
  bottom: "Block8_conv_3x1_2"
  top: "Block8_conv_3x1_2"
}
layer {
  name: "Block8_concat"
  type: "Concat"
  bottom: "Block8_conv_1x1"
  bottom: "Block8_conv_3x1_2"
  top: "Block8_concat"
}
layer {
  name: "Block8_conv_1x1_3"
  type: "Convolution"
  bottom: "Block8_concat"
  top: "Block8_conv_1x1_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 1792
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Block8_scaled"
  type: "Power"
  bottom: "Block8_conv_1x1_3"
  top: "Block8_scaled"
  power_param {
    power: 1.0
    scale: 1.0
    shift: 0.0
  }
}
layer {
  name: "Block8_output"
  type: "Eltwise"
  bottom: "inception_c5_output"
  bottom: "Block8_scaled"
  top: "Block8_output"
}
layer {
  name: "pool_8x8_s1"
  type: "Pooling"
  bottom: "Block8_output"
  top: "pool_8x8_s1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "pool_8x8_flatten"
  type: "Flatten"
  bottom: "pool_8x8_s1"
  top: "pool_8x8_flatten"
}
layer {
  name: "features"
  type: "InnerProduct"
  bottom: "pool_8x8_flatten"
  top: "features"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "features_bn_tr"
  type: "BatchNorm"
  bottom: "features"
  top: "features"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "features_bn"
  type: "BatchNorm"
  bottom: "features"
  top: "features"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.995000004768
    eps: 9.99999974738e-06
  }
}
layer {
  name: "Reduction1"
  type: "Reduction"
  bottom: "features"
  top: "Reduction1"
  reduction_param {
    operation: SUMSQ
    axis: 1
  }
}
layer {
  name: "Power1"
  type: "Power"
  bottom: "Reduction1"
  top: "Power1"
  power_param {
    power: -0.5
    shift: 9.99999996004e-13
  }
}
layer {
  name: "Reshape1"
  type: "Reshape"
  bottom: "Power1"
  top: "Reshape1"
  reshape_param {
    shape {
      dim: 1
    }
    axis: -1
    num_axes: 0
  }
}
layer {
  name: "Tile1"
  type: "Tile"
  bottom: "Reshape1"
  top: "Tile1"
  tile_param {
    axis: 1
    tiles: 512
  }
}
layer {
  name: "normed_features"
  type: "Eltwise"
  bottom: "features"
  bottom: "Tile1"
  top: "normed_features"
  eltwise_param {
    operation: PROD
  }
}
